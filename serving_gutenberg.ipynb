{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%env CUDA_VISIBILE_DEVICES=0,1,2,3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pprint import pprint\n",
    "from functools import partial\n",
    "from IPython.display import display, HTML\n",
    "from vllm import LLM, SamplingParams\n",
    "from omegaconf import DictConfig\n",
    "import torch\n",
    "from torchtune import config\n",
    "from torchtune.config._utils import _get_component_from_path\n",
    "from torch.utils.data import DataLoader, DistributedSampler\n",
    "from metaflow import Run, Task\n",
    "from utils import fetch_and_load_weights, load_gutenberg_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load from flow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Where to download the model on local disk?\n",
    "checkpoint_cache=\"./trained_models\"\n",
    "\n",
    "# Properties of upstream Metaflow run.\n",
    "from rewards_gutenberg_v1 import RewardServer\n",
    "reward_tag = 'reward:gutenberg_eras_v1'\n",
    "model_tag = 'model:meta-llama/Llama-3.2-3B-Instruct'\n",
    "flow_name = 'GutenbergErasGRPOPostTrain'\n",
    "\n",
    "artifact_name=\"model_ref\"\n",
    "\n",
    "# Properties of torchtune / finetuning run.\n",
    "# dataset_component = 'torchtune.dev.grpo.gsm8k.gsm8k_dataset'\n",
    "# dataset_partition = '3-5/100'\n",
    "# NOTE: Gutenberg is a custom dataset.\n",
    "\n",
    "# Inference server properties\n",
    "n_gpu = 4\n",
    "batch_size = 2\n",
    "grpo_size = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "task = Task('GutenbergErasGRPOPostTrain/9153/train/68625')\n",
    "model_dir = fetch_and_load_weights(\n",
    "    task=task,\n",
    "    reward_tag = reward_tag,\n",
    "    checkpoint_cache=checkpoint_cache\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load weights into memory. \n",
    "# vLLM optimizes layout automatically.\n",
    "llm = LLM(\n",
    "    model=model_dir, \n",
    "    task=\"generate\", \n",
    "    trust_remote_code=True,\n",
    "    tensor_parallel_size=n_gpu,\n",
    "    dtype='bfloat16'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Do inference, unrolling a single batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Setup torchtune dependencies.\n",
    "world_size = n_gpu\n",
    "rank = 0\n",
    "\n",
    "# NOTE: This repo contains a single validation file, small enough to fit in git repo.\n",
    "data_path = os.path.join(os.getcwd(), \"gutenberg_dataset\")\n",
    "\n",
    "cfg_tokenizer = DictConfig({\n",
    "    '_component_': 'torchtune.models.llama3.llama3_tokenizer',\n",
    "    'path': os.path.join(model_dir, 'original/tokenizer.model'),\n",
    "    'max_seq_len': 'null'\n",
    "})\n",
    "collate_fn = 'torchtune.dev.grpo.data.padded_collate_rl'\n",
    "\n",
    "tokenizer = config.instantiate(cfg_tokenizer)\n",
    "ds = load_gutenberg_dataset(tokenizer, data_path=data_path)\n",
    "collate_fn = _get_component_from_path(collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampler = DistributedSampler(\n",
    "    ds,\n",
    "    num_replicas=world_size,\n",
    "    rank=rank,\n",
    "    shuffle=True,\n",
    "    seed=42,\n",
    ")\n",
    "\n",
    "dataloader = DataLoader(\n",
    "    dataset=ds,\n",
    "    batch_size=batch_size,\n",
    "    sampler=sampler,\n",
    "    # dropping last avoids shape issues with compile + flex attention\n",
    "    drop_last=True,\n",
    "    collate_fn=(\n",
    "        partial(\n",
    "            collate_fn,\n",
    "            padding_idx=tokenizer.pad_id,\n",
    "        )\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## View `batch_size=2` sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = next(dataloader._get_iterator())\n",
    "tokens = batch[\"tokens\"]         # tokenized prompts\n",
    "answers = batch[\"answers\"]       # untokenized answers\n",
    "tokens = tokens                  # [batch_size x num_tokens_per_prompt]\n",
    "tokens_ls = tokens.tolist()\n",
    "out = []\n",
    "_prompts = []\n",
    "_answers = []\n",
    "for i in range(tokens.shape[0]):\n",
    "    prompt = tokenizer.decode(tokens_ls[i])\n",
    "    _prompts.extend([prompt] * grpo_size) \n",
    "    answer = answers[i]\n",
    "    _answers.extend([answer] * grpo_size)\n",
    "\n",
    "pprint(prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sample the LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_tokens = 512\n",
    "\n",
    "sampling_params = SamplingParams(\n",
    "    temperature=0.8, \n",
    "    top_p=0.95,\n",
    "    max_tokens=max_tokens\n",
    ")\n",
    "output = llm.generate(_prompts, sampling_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE: Unique to the model/tokenizer\n",
    "# This specific configuration is for meta-llama tokenizers.\n",
    "stop_token_ids = [\n",
    "    128001,\n",
    "    128009,\n",
    "    128008\n",
    "]\n",
    "pad_id = 128004\n",
    "\n",
    "data = []\n",
    "for o in output:\n",
    "    out_tokens = list(o.outputs[0].token_ids)\n",
    "    if len(out_tokens) < max_tokens:\n",
    "        out_tokens += [pad_id] * (max_tokens - len(out_tokens))\n",
    "    data.append(out_tokens)\n",
    "responses=torch.tensor(data, dtype=torch.int32).reshape(batch_size, grpo_size, max_tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pluggable Reward Server"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reward_server = RewardServer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rewards, successes, details = reward_server.batch_shaped_correctness_reward(\n",
    "  tokenizer=tokenizer,      \n",
    "  completions=responses,      \n",
    "  answers=_answers,\n",
    "  details_report=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_idx = 0\n",
    "group_member_idx = 0\n",
    "reward_server.print_reward_details_summary(details[batch_idx][group_member_idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "advantages = (rewards - rewards.mean(1, keepdim=True)) / (\n",
    "    rewards.std(1, keepdim=True) + 1e-4\n",
    ")\n",
    "# advantages = advantages.reshape(batch_size * grpo_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(HTML(\n",
    "    reward_server.display_responses(\n",
    "        responses,\n",
    "        tokenizer, \n",
    "        grpo_size, \n",
    "        advantages=advantages, \n",
    "        rewards=rewards, \n",
    "        successes=successes,\n",
    "        details=details\n",
    "    )\n",
    "))"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
